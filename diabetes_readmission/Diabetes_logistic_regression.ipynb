{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "## Overview\n",
    "\n",
    "A logistic regression can be used when the outcome we are interested in is a categorical one. In this case, we are interested in whether or not a patient was readmitted within 30 days -- an outcome with two categories (yes or no). \n",
    "\n",
    "## Running the Logistic Regression and Checking Results\n",
    "\n",
    "There a few things to note as this process happens. First, we'll read in the preprocessed data that has categorical features converted to separate, binary columns. Next, we'll split the data into a training and a test set. The training data is used to build the logistic model; it is the data that the model \"learns\" on. Once the model is constructed from the training data, we'll run it on the test data to make sure it generalizes -- or works on other data sets -- well. The test data was set aside before building the model precisely for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "readmit = pd.read_csv('diabetes_readmission_onehot.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# capture independent variables in list\n",
    "features = list(readmit) \n",
    "features = [e for e in features if e not in ('Unnamed: 0', 'readmit30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the data into a training and test set\n",
    "X = readmit[features].values\n",
    "y = readmit.readmit30.values \n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size = .2, \n",
    "                                                random_state = 7, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data set is split, we can set up the regression and run it. There are a few important things happening in this process. First is the creation of a grid of possible values for C, which is a tuning parameter used when data cannot be separated into two categories with a clean, straight line in the x-y plane. When a best attempt at such a line is drawn, some observations that belong to one category might still lie on the \"wrong\" side of the separating line. To account for this dynamic, we introduce a tuning parameter into the math of logistic regression. This step ideally creates a value of C that is neither too high nor too low. The former could create a model that is too biased toward the training data to be generalizable, and the latter could create a model with too much variance to have much predictive value (kind of like a jack of all trades being a master of none). \n",
    "\n",
    "The second tool at hand is the GridSearchCV function. The grid search allows us to perform an exhaustive search for the best C in just one line of code. The process also uses cross validation and an l2 penalty, which both help manage variance and in turn keep the model from becoming too general to the point that its predictive value is weakened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001} 0.807966339411\n"
     ]
    }
   ],
   "source": [
    "# create grid, run grid search w/ logistic regression, find best C and its accuracy score\n",
    "\n",
    "C_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]} #dictionary w/ C as key and possible values\n",
    "weights = {0: .1, 1: .9} # class weights to address imbalance of dependent variable \n",
    "clf_grid = GridSearchCV(LogisticRegression(penalty='l2', class_weight = weights), C_grid, \n",
    "                        cv = 5, scoring = 'accuracy') \n",
    "clf_grid.fit(Xtrain, Ytrain) #fit model on training data\n",
    "\n",
    "print(clf_grid.best_params_, clf_grid.best_score_) #output best C and best accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80852734922861147"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model accuracy on training data \n",
    "clf_grid_best = LogisticRegression(C = clf_grid.best_params_['C'], penalty='l2', \n",
    "                                    class_weight = weights)\n",
    "clf_grid_best.fit(Xtrain, Ytrain)\n",
    "\n",
    "x_pred_train = clf_grid_best.predict(Xtrain) #capture predictions for Y based on data in X\n",
    "accuracy_score(x_pred_train, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82436981075622706"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model accuracy on test data \n",
    "clf_grid_best.fit(Xtest, Ytest)\n",
    "x_pred_test = clf_grid_best.predict(Xtest)\n",
    "accuracy_score(x_pred_test, Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to accuracy, it often helps to check another metric called precision-recall. Precision-recall analysis reports various percentages for how well a model does at classifying observations accurately for an outcome. I'll talk about this more once we produce the numbers in classification reports below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.84      0.89     48616\n",
      "          1       0.24      0.52      0.33      4859\n",
      "\n",
      "avg / total       0.88      0.81      0.84     53475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for training data \n",
    "report_train = classification_report(Ytrain, x_pred_train) #classify actual Y values in test data vs. those predicted in X\n",
    "print(report_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.86      0.90     12154\n",
      "          1       0.26      0.50      0.34      1215\n",
      "\n",
      "avg / total       0.88      0.82      0.85     13369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for test data\n",
    "report_test = classification_report(Ytest, x_pred_test) \n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision reflects the percentage of positive (i.e., readmitted within 30 days) predictions that are correct. If the model classifies 100 observations as positive, and 80 of those were in fact positive, then the model's precision is .8 (or 80%). \n",
    "\n",
    "Recall captures the percent of true positives that are classified as positive. Returning to our model's context, if there were 1,000 patients readmitted within thirty days and the model detected 850 of them, then the model's recall would be .85 (or 85%).\n",
    "\n",
    "Finally, the F1-score (the harmonic mean) shows the weighted average of precision and recall. It is a useful metric because it factors in both false positives and false negatives. The model here has an F1-score of .85, which is pretty good considering that 1.00 would be a perfect score and .5 would be as good as random guessing. However, this higher score masks the model's weak performance with positive cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score vs. ROC Curve\n",
    "\n",
    "The chosen model (with the best C and accuracy score) has an accuracy score of about .824, which means that about 82.4% of the model's predictions made about readmission within 30 days were correct. While accuracy can be an okay starting point to assess model performance, it isn't necessarily the best one for this case. Accuracy score is usually better when the number of observations is equal for each category within a feature, so let's look at another performance metric -- the area under an ROC curve -- next. \n",
    "\n",
    "An ROC curve reflects how well a model differentiates positive (readmission within 30 days, in our case) and negative outcomes. A model making all predictions correctly has an area of 1. A model that performs no better than random guessing has an area of 0.5. As we'll see in a moment, the curve itself plots the true positive rate against the false positive rate to help observers gauge performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01} 0.784683277694\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with area under ROC curve as metric \n",
    "C_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]} \n",
    "clf_grid_ROC = GridSearchCV(LogisticRegression(penalty='l2', class_weight = weights), \n",
    "                            C_grid, cv = 5, scoring = 'roc_auc')\n",
    "clf_grid_ROC.fit(Xtrain, Ytrain) \n",
    "print(clf_grid_ROC.best_params_, clf_grid_ROC.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78994358026510514"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check ROC performance on training set\n",
    "clf_grid_ROC_best = LogisticRegression(penalty='l2', class_weight = weights, \n",
    "                                       C = clf_grid_ROC.best_params_['C'])\n",
    "clf_grid_ROC_best.fit(Xtrain, Ytrain)\n",
    "\n",
    "probs_train = clf_grid_ROC_best.predict_proba(Xtrain)\n",
    "preds_train = probs_train[:,1]\n",
    "roc_auc_score(Ytrain, preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79437791145322278"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check ROC performance on test set \n",
    "clf_grid_ROC_best.fit(Xtest, Ytest)\n",
    "\n",
    "probs_test = clf_grid_ROC_best.predict_proba(Xtest)\n",
    "preds_test = probs_test[:,1]\n",
    "roc_auc_score(Ytest, preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x131b35160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot ROC curve from test data\n",
    "fpr, tpr, threshold = roc_curve(Ytest, preds_test) #find true- and false-positive rates for relevant decision thresholds\n",
    "roc_auc = auc(fpr, tpr) #compute area under ROC curve using trapezoidal rule (not a binary classification here)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'blue', label = 'AUC = %0.4f' % roc_auc) #create line with AUC value for test data\n",
    "plt.plot([0, 1], [0, 1],'r--', label = 'AUC = .5') #create line with AUC=.5 for comparison\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A (theoretically) perfect ROC curve comprises a vertical line along the y-axis joined with a horizontal line at y = 1 (essentially an upside-down *L*. The closer our curve is to that ideal one, the better it is. So our model is looking pretty good at this point. Another line of comparison is the dotted red line, which represents at 50% success rate for binary predictions. If our model's line falls to this point, it is no better than randomly guessing would be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "A third way to evaluate model performance is a confusion matrix, which puts our model's predictions into four categories:\n",
    "\n",
    "- In the top-left quadrant is the number of observations classified as not readmitted within 30 days that were in fact not readmitted within 30 days. This is the true negative count. \n",
    "- In the top-right quadrant is the number of observations classified as readmitted within 30 days that were in fact not readmitted within 30 days. This is the false positive count. \n",
    "- In the lower left quadrant is the number of observations classified as not readmitted within 30 days that were in fact readmitted within 30 days. This is the false negative count. \n",
    "- In the lower right quadrant is the number of observations classified as readmitted within 30 days that were in fact readmitted within 30 days. This is the true positive count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0      1    All\n",
      "Actual                        \n",
      "0          40694   7922  48616\n",
      "1           2317   2542   4859\n",
      "All        43011  10464  53475\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for training data\n",
    "actual_train = pd.Series(Ytrain, name = 'Actual')\n",
    "predict_train = pd.Series(x_pred_train, name = 'Predicted') \n",
    "train_ct = pd.crosstab(actual_train, predict_train, margins = True) \n",
    "print(train_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for not readmitted: 0.837\n",
      "Training accuracy for readmitted (Recall): 0.523\n"
     ]
    }
   ],
   "source": [
    " # as percentages\n",
    "TN_train = train_ct.iloc[0,0] / train_ct.iloc[0,2]\n",
    "TP_train = train_ct.iloc[1,1] / train_ct.iloc[1,2]\n",
    "print('Training accuracy for not readmitted: {}'.format('%0.3f' % TN_train))\n",
    "print('Training accuracy for readmitted (Recall): {}'.format('%0.3f' % TP_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          10408  1746  12154\n",
      "1            602   613   1215\n",
      "All        11010  2359  13369\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for test data\n",
    "actual_test = pd.Series(Ytest, name = 'Actual')\n",
    "predict_test = pd.Series(x_pred_test, name = 'Predicted') \n",
    "test_ct = pd.crosstab(actual_test, predict_test, margins = True) \n",
    "print(test_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for not readmitted: 0.856\n",
      "Test accuracy for readmitted (Recall): 0.505\n"
     ]
    }
   ],
   "source": [
    " # as percentages\n",
    "TN_test = test_ct.iloc[0,0] / test_ct.iloc[0,2]\n",
    "TP_test = test_ct.iloc[1,1] / test_ct.iloc[1,2]\n",
    "print('Test accuracy for not readmitted: {}'.format('%0.3f' % TN_test))\n",
    "print('Test accuracy for readmitted (Recall): {}'.format('%0.3f' % TP_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does quite well predicting negative (labeled False in the matrices) cases, in which patients were not readmitted within thirty days. Percent accuracy is in the mid-80s. For positive cases, however, the model is just above 50% accuracy, which is just a little better than random chance. (You may also notice some overlap in the numbers here and those from the precision-recall part earlier.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Improvement Through Undersampling\n",
    "\n",
    "Although the accuracy for non-readmitted patients was quite good, the accuracy for positive cases (recall) was just slightly better than a random guess would be. Part of the reason for this issue might be the significant imblance in positive and negative outcomes. As we saw earlier, there are about 11 patients who were not readmitted within 30 days for every patient who was. In order to see if our model's performance is due to this imbalance, we can try the undersampling process with observations that did not show readmission within 30 days. Here, we'll use random undersampling to randomly choose fewer observations with the negative outcome in order to create a balance with positive outcomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# capture independent variables in list\n",
    "features = list(readmit) \n",
    "features = [e for e in features if e not in ('Unnamed: 0', 'readmit30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 6074, 1: 6074})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n",
    "X = readmit[features].values #majority class to be undersampled\n",
    "Y = readmit.readmit30.values \n",
    "\n",
    "rus = RandomUnderSampler(random_state = 31)\n",
    "X_res, Y_res = rus.fit_sample(X, Y)\n",
    "Counter(Y_res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train, test, split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_res, Y_res, test_size = .2, \n",
    "                                                random_state = 31, stratify = Y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01} 0.718769294093\n"
     ]
    }
   ],
   "source": [
    "# create grid, run grid search w/ logistic regression, find best C and its accuracy score\n",
    "C_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]} \n",
    "clf_grid = GridSearchCV(LogisticRegression(penalty='l2'), C_grid, cv = 5, scoring = 'accuracy') \n",
    "clf_grid.fit(Xtrain, Ytrain) \n",
    "\n",
    "print(clf_grid.best_params_, clf_grid.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72844206626877961"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model accuracy on training data \n",
    "clf_grid_best = LogisticRegression(C = clf_grid.best_params_['C'], penalty='l2')\n",
    "clf_grid_best.fit(Xtrain, Ytrain)\n",
    "\n",
    "x_pred_train = clf_grid_best.predict(Xtrain) #capture predictions for Y based on data in X\n",
    "accuracy_score(x_pred_train, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66255144032921809"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model accuracy on test data \n",
    "clf_grid_best.fit(Xtest, Ytest)\n",
    "\n",
    "x_pred_test = clf_grid_best.predict(Xtest)\n",
    "accuracy_score(x_pred_test, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           846   369  1215\n",
      "1           451   764  1215\n",
      "All        1297  1133  2430\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for logistic model w/ random undersampling\n",
    "actual = pd.Series(Ytest, name = 'Actual')\n",
    "predicted_rus = pd.Series(clf_grid_best.predict(Xtest), name = 'Predicted')\n",
    "ct_rus = pd.crosstab(actual, predicted_rus, margins = True)\n",
    "print(ct_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy for not readmitted: 0.696\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.629\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix with percentages\n",
    "TN_rus = ct_rus.iloc[0,0] / ct_rus.iloc[0,2]\n",
    "TP_rus = ct_rus.iloc[1,1] / ct_rus.iloc[1,2]\n",
    "print('Logistic Regression accuracy for not readmitted: {}'.format('%0.3f' % TN_rus))\n",
    "print('Logistic Regression accuracy for readmitted (Recall): {}'.format('%0.3f' % TP_rus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The undersampling approach improves the model's recall noticeably, although accuracy for negative cases suffered. We can try another technique called oversampling to see if further improvements are possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling (SMOTE)\n",
    "\n",
    "In addition to undersampling the majority class (not readmitted within 30 days), we can also try oversampling the minority class (readmitted within 30 days). Here, we'll use a common oversampling method called SMOTE (Synthetic Minority Oversampling Technique). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 60770, 1: 60770})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "X = readmit[features].values \n",
    "Y = readmit.readmit30.values #minority class to be oversampled\n",
    "\n",
    "sm = SMOTE(random_state = 31)\n",
    "X_resamp, Y_resamp = sm.fit_sample(X, Y)\n",
    "Counter(Y_resamp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train, test, split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_resamp, Y_resamp, test_size = .2, \n",
    "                                                random_state = 31, stratify = Y_resamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01} 0.724555701827\n"
     ]
    }
   ],
   "source": [
    "# create grid, run grid search w/ logistic regression, find best C and its accuracy score\n",
    "C_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]} \n",
    "clf_grid = GridSearchCV(LogisticRegression(penalty='l2'), C_grid, cv = 5, scoring = 'accuracy') \n",
    "clf_grid.fit(Xtrain, Ytrain) \n",
    "\n",
    "print(clf_grid.best_params_, clf_grid.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72503908178377485"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model accuracy on training data \n",
    "clf_grid_best = LogisticRegression(C = clf_grid.best_params_['C'], penalty='l2')\n",
    "clf_grid_best.fit(Xtrain, Ytrain)\n",
    "\n",
    "x_pred_train = clf_grid_best.predict(Xtrain) #capture predictions for Y based on data in X\n",
    "accuracy_score(x_pred_train, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72766167516866875"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model accuracy on test data \n",
    "clf_grid_best.fit(Xtest, Ytest)\n",
    "\n",
    "x_pred_test = clf_grid_best.predict(Xtest)\n",
    "accuracy_score(x_pred_test, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0      1    All\n",
      "Actual                        \n",
      "0           9487   2667  12154\n",
      "1           3953   8201  12154\n",
      "All        13440  10868  24308\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix with SMOTE oversampling\n",
    "actual = pd.Series(Ytest, name = 'Actual')\n",
    "predicted_sm = pd.Series(clf_grid_best.predict(Xtest), name = 'Predicted')\n",
    "ct_sm = pd.crosstab(actual, predicted_sm, margins = True)\n",
    "print(ct_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for not readmitted: 0.781\n",
      "Accuracy for readmitted (Recall): 0.675\n",
      "Correct Positive Predictions (Precision): 0.755\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix with percentages\n",
    "TN_sm = ct_sm.iloc[0,0] / ct_sm.iloc[0,2]\n",
    "TP_sm = ct_sm.iloc[1,1] / ct_sm.iloc[1,2]\n",
    "Prec_sm = ct_sm.iloc[1,1] / ct_sm.iloc[2,1] \n",
    "print('Accuracy for not readmitted: {}'.format('%0.3f' % TN_sm))\n",
    "print('Accuracy for readmitted (Recall): {}'.format('%0.3f' % TP_sm))\n",
    "print('Correct Positive Predictions (Precision): {}'.format('%0.3f' % Prec_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The oversampling approach improved accuracy for both positive and negative cases when compared with undersampling. The global accuracy (about 73%) is a little lower than it was in the original model (about 80%), but the trade-off to improve recall is likely worth it. Predictive value with respect to the positive class is more valuable, so the oversampling model is our best choice with logistic regression.\n",
    "\n",
    "The ten features with the highest predictive values with respect to readmission are reproduced below. (In the interest of brevity, I did not reproduce full models.) \n",
    "\n",
    "A higher coefficient in logistic regression indicates a higher effect on the odds of readmission within 30 days. For example, mathematically, num_visits (number of hospital visits) has a coefficient of 0.589. This means that, controlling for other model variables, the estimated odds of readmission are e^0.589 = 1.802 times higher for each additional visit that a patient makes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.589403</td>\n",
       "      <td>num_visits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.284375</td>\n",
       "      <td>number_inpatient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.180511</td>\n",
       "      <td>discharge_disposition_id_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.138675</td>\n",
       "      <td>discharge_disposition_id_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.082984</td>\n",
       "      <td>first_diag_injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.076460</td>\n",
       "      <td>discharge_disposition_id_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.072813</td>\n",
       "      <td>age_[70-80)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.069777</td>\n",
       "      <td>num_lab_procs_[61-70]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.064836</td>\n",
       "      <td>age_[60-70)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.059289</td>\n",
       "      <td>glipizide_Steady</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     coefficient                      feature\n",
       "7       0.589403                   num_visits\n",
       "5       0.284375             number_inpatient\n",
       "31      0.180511   discharge_disposition_id_3\n",
       "44      0.138675  discharge_disposition_id_22\n",
       "121     0.082984            first_diag_injury\n",
       "33      0.076460   discharge_disposition_id_5\n",
       "20      0.072813                  age_[70-80)\n",
       "150     0.069777        num_lab_procs_[61-70]\n",
       "19      0.064836                  age_[60-70)\n",
       "89      0.059289             glipizide_Steady"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature evaluation for logistic regression\n",
    "logistic_coefs = clf_grid_best.coef_[0]\n",
    "logistic_coef_df = pd.DataFrame({'feature': features, 'coefficient': logistic_coefs})\n",
    "logistic_df = logistic_coef_df.sort_values('coefficient', ascending = False)\n",
    "logistic_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Looping Processes to Correct Imbalanced Data\n",
    "\n",
    "Now that successful corrections for the imbalanced dependent variable have been made, we can check repeat those processes a few times to ensure that we didn't \"just get lucky\" with the one-off uses of random undersampling and SMOTE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# capture independent variables in list\n",
    "features = list(readmit) \n",
    "features = [e for e in features if e not in ('Unnamed: 0', 'readmit30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "X = readmit[features].values #majority class to be undersampled\n",
    "Y = readmit.readmit30.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 6074, 0: 6074})\n",
      "{'C': 0.001} 0.713624202511\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           936   279  1215\n",
      "1           410   805  1215\n",
      "All        1346  1084  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.770\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.663\n",
      "Logistic Regression trial count: 1\n",
      "\n",
      "Counter({1: 6074, 0: 6074})\n",
      "{'C': 0.01} 0.710022638403\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           967   248  1215\n",
      "1           420   795  1215\n",
      "All        1387  1043  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.796\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.654\n",
      "Logistic Regression trial count: 2\n",
      "\n",
      "Counter({1: 6074, 0: 6074})\n",
      "{'C': 0.001} 0.715990944639\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           870   345  1215\n",
      "1           413   802  1215\n",
      "All        1283  1147  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.716\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.660\n",
      "Logistic Regression trial count: 3\n",
      "\n",
      "Counter({1: 6074, 0: 6074})\n",
      "{'C': 0.01} 0.71043424573\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           968   247  1215\n",
      "1           419   796  1215\n",
      "All        1387  1043  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.797\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.655\n",
      "Logistic Regression trial count: 4\n",
      "\n",
      "Counter({1: 6074, 0: 6074})\n",
      "{'C': 0.001} 0.707450092612\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           948   267  1215\n",
      "1           365   850  1215\n",
      "All        1313  1117  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.780\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.700\n",
      "Logistic Regression trial count: 5\n",
      "\n",
      "Counter({1: 6074, 0: 6074})\n",
      "{'C': 0.001} 0.718151883104\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           873   342  1215\n",
      "1           404   811  1215\n",
      "All        1277  1153  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.719\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.667\n",
      "Logistic Regression trial count: 6\n",
      "\n",
      "Counter({1: 6074, 0: 6074})\n",
      "{'C': 0.001} 0.721341839885\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           929   286  1215\n",
      "1           433   782  1215\n",
      "All        1362  1068  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.765\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.644\n",
      "Logistic Regression trial count: 7\n",
      "\n",
      "Counter({1: 6074, 0: 6074})\n",
      "{'C': 0.01} 0.713932908006\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           986   229  1215\n",
      "1           400   815  1215\n",
      "All        1386  1044  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.812\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.671\n",
      "Logistic Regression trial count: 8\n",
      "\n",
      "Counter({1: 6074, 0: 6074})\n",
      "{'C': 0.01} 0.704157233999\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           967   248  1215\n",
      "1           422   793  1215\n",
      "All        1389  1041  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.796\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.653\n",
      "Logistic Regression trial count: 9\n",
      "\n",
      "Counter({1: 6074, 0: 6074})\n",
      "{'C': 0.001} 0.717534472114\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           894   321  1215\n",
      "1           401   814  1215\n",
      "All        1295  1135  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.736\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.670\n",
      "Logistic Regression trial count: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# multiple calls of RandomUnderSampler\n",
    "\n",
    "n_trials = 10 # number of trials\n",
    "\n",
    "# Declare empty lists for true-positive and true-negative rates\n",
    "TNR = []\n",
    "TPR = [] \n",
    "\n",
    "# for loop such that variable \"trial\" varies from 0 to n_trials-1 \n",
    " # which means the loop executes n_trials times\n",
    "for trial in range(n_trials):\n",
    "    \n",
    "    # assume that X and Y are already defined, use RandomUnderSampler\n",
    "    rus = RandomUnderSampler(random_state = 31*trial) # randomized seed\n",
    "    X_res, Y_res = rus.fit_sample(X, Y)\n",
    "    print(Counter(Y_res)) #print results for Counter for each sample (trial)\n",
    "    \n",
    "    # train/test split\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_res, Y_res, test_size = .2, \n",
    "                                                    stratify = Y_res, random_state = 2*trial)\n",
    "    \n",
    "    # fit hyper-parameter\n",
    "    # create grid, run grid search w/ logistic regression, find best C and its accuracy score\n",
    "    C_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]} \n",
    "    clf_grid = GridSearchCV(LogisticRegression(penalty='l2'), C_grid, cv = 5, scoring = 'accuracy') \n",
    "    clf_grid.fit(Xtrain, Ytrain) \n",
    "    print(clf_grid.best_params_, clf_grid.best_score_) \n",
    "    \n",
    "    # use that parameter with Logistic regression\n",
    "    # check model accuracy on training data \n",
    "    clf_grid_best = LogisticRegression(C = clf_grid.best_params_['C'], penalty='l2')\n",
    "    clf_grid_best.fit(Xtrain, Ytrain)\n",
    "    x_pred_train = clf_grid_best.predict(Xtrain) #capture predictions for Y based on data in X\n",
    "    accuracy_score(x_pred_train, Ytrain)\n",
    "    \n",
    "    # check model accuracy on test data \n",
    "    clf_grid_best.fit(Xtest, Ytest)\n",
    "    x_pred_test = clf_grid_best.predict(Xtest)\n",
    "    accuracy_score(x_pred_test, Ytest)\n",
    "    \n",
    "    # confusion matrix for logistic model w/ random undersampling\n",
    "    actual = pd.Series(Ytest, name = 'Actual')\n",
    "    predicted_rus = pd.Series(clf_grid_best.predict(Xtest), name = 'Predicted')\n",
    "    ct_rus = pd.crosstab(actual, predicted_rus, margins = True)\n",
    "    print(ct_rus)\n",
    "    \n",
    "    # capture given trial's true negative rate, add to array\n",
    "    tnr = ct_rus.iloc[0,0] / ct_rus.iloc[0,2]\n",
    "    TNR.append(tnr)\n",
    "    \n",
    "    # same process for true positive rate\n",
    "    tpr = ct_rus.iloc[1,1] / ct_rus.iloc[1,2]\n",
    "    TPR.append(tpr)\n",
    "    \n",
    "    # print TNR, TPR, and trial no.\n",
    "    print('Logistic Regression accuracy for not readmitted: {}'.format('%0.3f' % tnr))\n",
    "    print('Logistic Regression accuracy for readmitted (Recall): {}'.format('%0.3f' % tpr))\n",
    "    print('Logistic Regression trial count: {}'.format(trial + 1))\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAERCAYAAACKHYuuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113112208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot TNR and TPR as box plots\n",
    "plots = pd.DataFrame({'TPR': TPR, 'TNR': TNR})\n",
    "\n",
    "sns.boxplot(data = plots)  \n",
    "plt.title('Box Plots for TPR and TNR in Random \\n Undersampling (Logistic Regression)')\n",
    "plt.ylabel('Percent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 60770, 0: 60770})\n",
      "{'C': 0.001} 0.719901214242\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           939   276  1215\n",
      "1           409   806  1215\n",
      "All        1348  1082  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.773\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.663\n",
      "Logistic Regression trial count: 1\n",
      "\n",
      "Counter({1: 60770, 0: 60770})\n",
      "{'C': 0.01} 0.720518625232\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           952   263  1215\n",
      "1           415   800  1215\n",
      "All        1367  1063  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.784\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.658\n",
      "Logistic Regression trial count: 2\n",
      "\n",
      "Counter({1: 60770, 0: 60770})\n",
      "{'C': 0.001} 0.715270631817\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           909   306  1215\n",
      "1           399   816  1215\n",
      "All        1308  1122  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.748\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.672\n",
      "Logistic Regression trial count: 3\n",
      "\n",
      "Counter({1: 60770, 0: 60770})\n",
      "{'C': 0.001} 0.717019962955\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           908   307  1215\n",
      "1           373   842  1215\n",
      "All        1281  1149  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.747\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.693\n",
      "Logistic Regression trial count: 4\n",
      "\n",
      "Counter({1: 60770, 0: 60770})\n",
      "{'C': 0.001} 0.713212595184\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           936   279  1215\n",
      "1           358   857  1215\n",
      "All        1294  1136  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.770\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.705\n",
      "Logistic Regression trial count: 5\n",
      "\n",
      "Counter({1: 60770, 0: 60770})\n",
      "{'C': 0.001} 0.710845853056\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           949   266  1215\n",
      "1           409   806  1215\n",
      "All        1358  1072  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.781\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.663\n",
      "Logistic Regression trial count: 6\n",
      "\n",
      "Counter({1: 60770, 0: 60770})\n",
      "{'C': 0.001} 0.718975097757\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           907   308  1215\n",
      "1           389   826  1215\n",
      "All        1296  1134  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.747\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.680\n",
      "Logistic Regression trial count: 7\n",
      "\n",
      "Counter({1: 60770, 0: 60770})\n",
      "{'C': 0.01} 0.71671125746\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           974   241  1215\n",
      "1           413   802  1215\n",
      "All        1387  1043  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.802\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.660\n",
      "Logistic Regression trial count: 8\n",
      "\n",
      "Counter({1: 60770, 0: 60770})\n",
      "{'C': 0.001} 0.719386705083\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           905   310  1215\n",
      "1           418   797  1215\n",
      "All        1323  1107  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.745\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.656\n",
      "Logistic Regression trial count: 9\n",
      "\n",
      "Counter({1: 60770, 0: 60770})\n",
      "{'C': 0.01} 0.717740275777\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           977   238  1215\n",
      "1           428   787  1215\n",
      "All        1405  1025  2430\n",
      "Logistic Regression accuracy for not readmitted: 0.804\n",
      "Logistic Regression accuracy for readmitted (Recall): 0.648\n",
      "Logistic Regression trial count: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# multiple calls of SMOTE\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "n_trials = 10 # number of trials\n",
    "\n",
    "# Declare empty lists for true-positive and true-negative rates\n",
    "TNR_smote = []\n",
    "TPR_smote = [] \n",
    "\n",
    "# for loop such that variable \"trial\" varies from 0 to n_trials-1 \n",
    " # which means the loop executes n_trials times\n",
    "for trial in range(n_trials):\n",
    "    \n",
    "    # assume that X and Y are already defined, use RandomUnderSampler\n",
    "    sm = SMOTE(random_state = 31*trial) #randomize seed\n",
    "    X_resamp, Y_resamp = sm.fit_sample(X, Y)\n",
    "    print(Counter(Y_resamp)) #print results for Counter for each sample (trial)\n",
    "        \n",
    "    # train/test split\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_res, Y_res, test_size = .2, \n",
    "                                                    stratify = Y_res)\n",
    "    \n",
    "    # fit hyper-parameter\n",
    "    # create grid, run grid search w/ logistic regression, find best C and its accuracy score\n",
    "    C_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]} \n",
    "    clf_grid = GridSearchCV(LogisticRegression(penalty='l2'), C_grid, cv = 5, \n",
    "                            scoring = 'accuracy') \n",
    "    clf_grid.fit(Xtrain, Ytrain) \n",
    "    print(clf_grid.best_params_, clf_grid.best_score_) \n",
    "    \n",
    "    # use that parameter with Logistic regression\n",
    "    # check model accuracy on training data \n",
    "    clf_grid_best = LogisticRegression(C = clf_grid.best_params_['C'], penalty='l2')\n",
    "    clf_grid_best.fit(Xtrain, Ytrain)\n",
    "    x_pred_train = clf_grid_best.predict(Xtrain) #capture predictions for Y based on data in X\n",
    "    accuracy_score(x_pred_train, Ytrain)\n",
    "    \n",
    "    # check model accuracy on test data \n",
    "    clf_grid_best.fit(Xtest, Ytest)\n",
    "    x_pred_test = clf_grid_best.predict(Xtest)\n",
    "    accuracy_score(x_pred_test, Ytest)\n",
    "    \n",
    "    # confusion matrix for logistic model w/ SMOTE\n",
    "    actual = pd.Series(Ytest, name = 'Actual')\n",
    "    predicted_sm = pd.Series(clf_grid_best.predict(Xtest), name = 'Predicted')\n",
    "    ct_sm = pd.crosstab(actual, predicted_sm, margins = True)\n",
    "    print(ct_sm)\n",
    "\n",
    "    # capture given trial's true negative rate, add to array\n",
    "    tnr_smote = ct_sm.iloc[0,0] / ct_sm.iloc[0,2]\n",
    "    TNR_smote.append(tnr_smote)\n",
    "    \n",
    "    # same process for true positive rate\n",
    "    tpr_smote = ct_sm.iloc[1,1] / ct_sm.iloc[1,2]\n",
    "    TPR_smote.append(tpr_smote)\n",
    "    \n",
    "    # print TNR, TPR, and trial no.\n",
    "    print('Logistic Regression accuracy for not readmitted: {}'.format('%0.3f' % tnr_smote))\n",
    "    print('Logistic Regression accuracy for readmitted (Recall): {}'.format('%0.3f' % tpr_smote))\n",
    "    print('Logistic Regression trial count: {}'.format(trial + 1))\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEFCAYAAAAMk/uQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126c31c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot SMOTE TNR and TPR as box plots\n",
    "plots_smote = pd.DataFrame({'TPR': TPR_smote, 'TNR': TNR_smote})\n",
    "\n",
    "sns.boxplot(data = plots_smote) \n",
    "plt.title('Box Plots for TPR and TNR in SMOTE (Logistic Regression)')\n",
    "plt.ylabel('Percent')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
