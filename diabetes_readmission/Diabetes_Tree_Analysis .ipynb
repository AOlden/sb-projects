{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tree-based Analyses\n",
    "\n",
    "Decision trees work kind of like a game of 20 Questions. They consider each variable in a dataset and finding its \"split point.\" Variables with more predictive power will be used earlier in the splitting process. For example, imagine a set of data showing the freshness of various vegetables, and we want to predict whether they have spoiled or not. If one of the features is the farm of origin, and 80% of spoiled vegetables come from one particular farm, then the farm-of-origin feature will have high predictive value and be used early on in the tree-building process. From there, additional features would be considered to determine their value in predicting freshness. \n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "When using a simple tree, it is easy to produce a visualization (with a tree shape, of course) that shows splits and features in decreasing order of importance moving down the \"tree.\" However, in this particular instance, I'm using AdaBoost, which is version of boosted trees that offers more powerful predictions. The output in this case is a bit different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "import pandas as pd\n",
    "\n",
    "#import mapped version of data set here\n",
    "readmit = pd.read_csv('diabetes_readmission_onehot.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# capture independent variables in list\n",
    "features = list(readmit)\n",
    "features = [e for e in features if e not in ('Unnamed: 0', 'readmit30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the data into a training and test set\n",
    "X = readmit[features].values\n",
    "y = readmit.readmit30.values\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size = .2, \n",
    "                                                random_state = 31, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847856982572\n"
     ]
    }
   ],
   "source": [
    "# build model on training data\n",
    "dt = DecisionTreeClassifier() \n",
    "clf = AdaBoostClassifier(base_estimator = dt, n_estimators = 50, learning_rate = 1, \n",
    "                         random_state = 7)\n",
    "model = clf.fit(Xtrain, Ytrain)\n",
    "\n",
    "# check performance (model accuracy) on test data\n",
    "print(model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Confusion Matrix and Recall Score\n",
    "\n",
    "Another way to evaluate model performance is a confustion matrix, which puts our model's predictions into four categories:\n",
    "\n",
    "- In the top-left quadrant is the number of observations classified as not readmitted within 30 days that were in fact not readmitted within 30 days. This is the true negative count. \n",
    "- In the top-right quadrant is the number of observations classified as readmitted within 30 days that were in fact not readmitted within 30 days. This is the false positive count. \n",
    "- In the lower left quadrant is the number of observations classified as not readmitted within 30 days that were in fact readmitted within 30 days. This is the false negative count. \n",
    "- In the lower right quadrant is the number of observations classified as readmitted within 30 days that were in fact readmitted within 30 days. This is the true positive count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          11062  1092  12154\n",
      "1            942   273   1215\n",
      "All        12004  1365  13369\n"
     ]
    }
   ],
   "source": [
    "# set actual and predicted vectors; generate confusion matrix for test data\n",
    "actual = pd.Series(Ytest, name = 'Actual')\n",
    "predicted = pd.Series(clf.predict(Xtest), name = 'Predicted')\n",
    "train_ct = pd.crosstab(actual, predicted, margins = True)\n",
    "print(train_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for not readmitted: 0.910\n",
      "Accuracy for readmitted (Recall): 0.225\n"
     ]
    }
   ],
   "source": [
    " # as percentages\n",
    "TN = train_ct.iloc[0,0] / train_ct.iloc[0,2]\n",
    "TP = train_ct.iloc[1,1] / train_ct.iloc[1,2]\n",
    "print('Accuracy for not readmitted: {}'.format('%0.3f' % TN))\n",
    "print('Accuracy for readmitted (Recall): {}'.format('%0.3f' % TP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can consider the model's recall score. Recall is a (percentage) measure of how many positive cases were identified correctly. In the context of this analysis, if 100 patients were readmitted within thirty days and the model classified 81 of them as such, then the model's recall would be .81 (or 81%). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement Through Undersampling\n",
    "\n",
    "The AdaBoost algorithm had subpar performance metrics, as evidenced by recall scores (although their accuracy scores were pretty good). The cause may be the significant imblance in positive and negative outcomes. As we saw earlier, there are about 11 patients who were not readmitted within 30 days for every patient who was. In order to see if our model's performance is due to this imbalance, we can try the undersampling process on observations that did not show readmission within 30 days. Here, we'll use random undersampling to randomly choose fewer observations with the negative outcome in order to create a balance with positive outcomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 6074, 1: 6074})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n",
    "X = readmit[features].values #majority class to be undersampled\n",
    "Y = readmit.readmit30.values \n",
    "\n",
    "rus = RandomUnderSampler(random_state = 31)\n",
    "X_res, Y_res = rus.fit_sample(X, Y)\n",
    "Counter(Y_res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train, test, split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_res, Y_res, test_size = .2, \n",
    "                                                random_state = 31, stratify = Y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run AdaBoost again w/ undersampled dataset\n",
    "dt_rus = DecisionTreeClassifier() \n",
    "clf_rus = AdaBoostClassifier(base_estimator = dt_rus, n_estimators = 50, learning_rate = 1, \n",
    "                             random_state = 7)\n",
    "model = clf_rus.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           805   410  1215\n",
      "1           430   785  1215\n",
      "All        1235  1195  2430\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for random forest with random undersampling\n",
    "actual = pd.Series(Ytest, name = 'Actual')\n",
    "predicted_rus = pd.Series(clf_rus.predict(Xtest), name = 'Predicted')\n",
    "ct_rus = pd.crosstab(actual, predicted_rus, margins = True)\n",
    "print(ct_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost accuracy for not readmitted: 0.663\n",
      "AdaBoost accuracy for readmitted (Recall): 0.646\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix with percentages\n",
    "TN_rus = ct_rus.iloc[0,0] / ct_rus.iloc[0,2]\n",
    "TP_rus = ct_rus.iloc[1,1] / ct_rus.iloc[1,2]\n",
    "print('AdaBoost accuracy for not readmitted: {}'.format('%0.3f' % TN_rus))\n",
    "print('AdaBoost accuracy for readmitted (Recall): {}'.format('%0.3f' % TP_rus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The undersampling approach improves the model significantly with respect to positive cases. It's noticeably better than random chance would be, too. Before finishing, we can also compare these results with another technique for handling imbalanced data: oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling (SMOTE)\n",
    "\n",
    "In addition to undersampling the majority class (not readmitted within 30 days), we can also try oversampling the minority class (readmitted within 30 days). Here, we'll use a common oversampling method called SMOTE (Synthetic Minority Oversampling Technique). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 60770, 1: 60770})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "X = readmit[features].values \n",
    "Y = readmit.readmit30.values #minority class to be oversampled\n",
    "\n",
    "sm = SMOTE(random_state = 31)\n",
    "X_resamp, Y_resamp = sm.fit_sample(X, Y)\n",
    "Counter(Y_resamp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train, test, split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_resamp, Y_resamp, test_size = .2, \n",
    "                                                random_state = 31, stratify = Y_resamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdaBoostClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-78d435cdd0d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run AdaBoost again w/ oversampled dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m clf_sm = AdaBoostClassifier(base_estimator = dt, n_estimators = 50, learning_rate = 1, \n\u001b[0m\u001b[1;32m      3\u001b[0m                          random_state = 7)\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_sm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_sm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_sm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AdaBoostClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# run AdaBoost again w/ oversampled dataset\n",
    "clf_sm = AdaBoostClassifier(base_estimator = dt, n_estimators = 50, learning_rate = 1, \n",
    "                         random_state = 7)\n",
    "model_sm = clf_sm.fit(Xtrain, Ytrain)\n",
    "print(model_sm.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0      1    All\n",
      "Actual                        \n",
      "0          12062     92  12154\n",
      "1           1121  11033  12154\n",
      "All        13183  11125  24308\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix with SMOTE oversampling\n",
    "actual = pd.Series(Ytest, name = 'Actual')\n",
    "predicted_sm = pd.Series(clf_sm.predict(Xtest), name = 'Predicted')\n",
    "ct_sm = pd.crosstab(actual, predicted_sm, margins = True)\n",
    "print(ct_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for not readmitted: 0.992\n",
      "Accuracy for readmitted (Recall): 0.908\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix with percentages\n",
    "TN_sm = ct_sm.iloc[0,0] / ct_sm.iloc[0,2]\n",
    "TP_sm = ct_sm.iloc[1,1] / ct_sm.iloc[1,2]\n",
    "print('Accuracy for not readmitted: {}'.format('%0.3f' % TN_sm))\n",
    "print('Accuracy for readmitted (Recall): {}'.format('%0.3f' % TP_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both accuracy and recall have been greatly improved from the model using undersampling. In our case, AdaBoost works best with oversampling the minority class (readmitted within 30 days) rather than undersampling the majority class (not readmitted within 30 days). This may stem from the fact that oversampling generates more overall data, which generally improves the machine-learning process since the model has more data to \"learn\" from. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random Forest\n",
    "\n",
    "Individual decision trees are weak learners, meaning that their accuracy is limited (often not much higher than 50%). In order to improve accuracy, we can take an ensemble approach, random forest, that combines multiple trees. The idea is that many weak learners combine their \"knowledge\" to create a strong learner, which is much more accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data into a training and test set\n",
    "X = readmit[features].values\n",
    "y = readmit.readmit30.values\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size = .2, \n",
    "                                                random_state = 31, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build and fit model with random forest\n",
    "clf_rf = RandomForestClassifier(random_state = 7, class_weight = {0: .1, 1: .9})\n",
    "model_rf = clf_rf.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.906350512379\n"
     ]
    }
   ],
   "source": [
    "# model accuracy on test data\n",
    "print(model_rf.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0   1    All\n",
      "Actual                     \n",
      "0          12098  56  12154\n",
      "1           1196  19   1215\n",
      "All        13294  75  13369\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "actual = pd.Series(Ytest, name = 'Actual')\n",
    "predicted_rf = pd.Series(clf_rf.predict(Xtest), name = 'Predicted')\n",
    "rf_ct = pd.crosstab(actual, predicted_rf, margins = True)\n",
    "print(rf_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for not readmitted: 0.995\n",
      "Accuracy for readmitted (Recall): 0.016\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix with percentages\n",
    "TN_rf = rf_ct.iloc[0,0] / rf_ct.iloc[0,2]\n",
    "TP_rf = rf_ct.iloc[1,1] / rf_ct.iloc[1,2]\n",
    "print('Accuracy for not readmitted: {}'.format('%0.3f' % TN_rf))\n",
    "print('Accuracy for readmitted (Recall): {}'.format('%0.3f' % TP_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement Through Undersampling: Random Forest\n",
    "\n",
    "The initial random forest did not show great results. Let's see if the undersampling method helps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 6074, 1: 6074})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = readmit[features].values #majority class to be undersampled\n",
    "Y = readmit.readmit30.values \n",
    "\n",
    "rus = RandomUnderSampler(random_state = 34)\n",
    "X_res, Y_res = rus.fit_sample(X, Y)\n",
    "Counter(Y_res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train, test, split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_res, Y_res, test_size = .2, \n",
    "                                                random_state = 34, stratify = Y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.707407407407\n"
     ]
    }
   ],
   "source": [
    "# run random forest again w/ undersampled dataset\n",
    "rf_rus = RandomForestClassifier(random_state = 34)\n",
    "rf_model_rus = rf_rus.fit(Xtrain, Ytrain)\n",
    "print(rf_model_rus.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           912   303  1215\n",
      "1           408   807  1215\n",
      "All        1320  1110  2430\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for random forest with random undersampling\n",
    "actual = pd.Series(Ytest, name = 'Actual')\n",
    "predicted_rf_rus = pd.Series(rf_rus.predict(Xtest), name = 'Predicted')\n",
    "ct_rf_rus = pd.crosstab(actual, predicted_rf_rus, margins = True)\n",
    "print(ct_rf_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for not readmitted: 0.751\n",
      "Accuracy for readmitted (Recall): 0.664\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix with percentages\n",
    "TN_rf_rus = ct_rf_rus.iloc[0,0] / ct_rf_rus.iloc[0,2]\n",
    "TP_rf_rus = ct_rf_rus.iloc[1,1] / ct_rf_rus.iloc[1,2]\n",
    "print('Accuracy for not readmitted: {}'.format('%0.3f' % TN_rf_rus))\n",
    "print('Accuracy for readmitted (Recall): {}'.format('%0.3f' % TP_rf_rus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for non-readmitted patients has dropped, which may be due to the fact that we had less data from that class this time. But the performance in that class is still well above a random guess. More importantly, the accuracy with respect to positive cases (readmitted within 30 days) is vastly improved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling: Random Forest\n",
    "\n",
    "Here, we'll try the oversampling method with the Random Forest classifier, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 60770, 1: 60770})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = readmit[features].values \n",
    "Y = readmit.readmit30.values #minority class to be oversampled\n",
    "\n",
    "sm = SMOTE(random_state = 137)\n",
    "X_resamp, Y_resamp = sm.fit_sample(X, Y)\n",
    "Counter(Y_resamp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train, test, split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_resamp, Y_resamp, test_size = .2, \n",
    "                                                random_state = 137, stratify = Y_resamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.950674675004\n"
     ]
    }
   ],
   "source": [
    "# run random forest again w/ oversampled dataset\n",
    "clf_rf_sm = RandomForestClassifier(random_state = 137)\n",
    "model_rf_sm = clf_rf_sm.fit(Xtrain, Ytrain)\n",
    "print(model_rf_sm.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0      1    All\n",
      "Actual                        \n",
      "0          12063     91  12154\n",
      "1           1108  11046  12154\n",
      "All        13171  11137  24308\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for random forest with SMOTE oversampling\n",
    "actual = pd.Series(Ytest, name = 'Actual')\n",
    "predicted_rf_sm = pd.Series(clf_rf_sm.predict(Xtest), name = 'Predicted')\n",
    "ct_rf_sm = pd.crosstab(actual, predicted_rf_sm, margins = True)\n",
    "print(ct_rf_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for not readmitted: 0.993\n",
      "Accuracy for readmitted (Recall): 0.909\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix with percentages\n",
    "TN_rf_sm = ct_rf_sm.iloc[0,0] / ct_rf_sm.iloc[0,2]\n",
    "TP_rf_sm = ct_rf_sm.iloc[1,1] / ct_rf_sm.iloc[1,2]\n",
    "print('Accuracy for not readmitted: {}'.format('%0.3f' % TN_rf_sm))\n",
    "print('Accuracy for readmitted (Recall): {}'.format('%0.3f' % TP_rf_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for patients not readmitted is nearly perfect in the SMOTE model, and its accuracy for positive cases is excellent as well. This model seems like our best one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature analysis\n",
    "\n",
    "# summary of feature importance\n",
    "importance = model.feature_importances_\n",
    "importance_df = pd.DataFrame({'feature': features, 'importance': importance})\n",
    "imp = importance_df.sort_values('importance', ascending = False)\n",
    "imp.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
