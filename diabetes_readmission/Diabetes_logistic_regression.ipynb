{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "## Overview\n",
    "\n",
    "A logistic regression is used when the outcome we are interested in is a categorical one. In this case, we are interested in whether or not a patient was readmitted within 30 days -- an outcome with two categories (yes or no). There are a few steps to take before running the regression, though.\n",
    "\n",
    "## Preparing to Map Features\n",
    "Before running a logistic regression, it is important to map categorical features into separate, binary variables for each of their categories (more information on that process soon). But first, we need to prepare a few variables for mapping. First, the number of lab procedures ranges from 1-132, but in some cases there are very few patients who had a given number of procedures. To keep a desirable ratio of new binary variables to actual observations, we'll first bin the number of procedures so that there are only 13 new variables, which will make machine-learning techniques more fruitful. \n",
    "\n",
    "There are also a few ID features (e.g., admission type ID) that are functionally categorical but have numeric values. We'll change their data types so that we can map those variables accordingly, too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Logistic Regression and Checking Results\n",
    "\n",
    "Now we are ready to perform the regression. There a few things to note as this process happens. The first step is to split the data into a training and a test set. The training data is used to build the logistic model; it is the data that the model \"learns\" on. Once the model is constructed from the training data, we'll run it on the test data to make sure it generalizes -- or works on other data sets -- well. The test data was set aside before building the model precisely for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "readmit = pd.read_csv('diabetes_readmission_onehot.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# capture independent variables in list\n",
    "features = list(readmit) \n",
    "features = [e for e in features if e not in ('Unnamed: 0', 'readmit30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the data into a training and test set\n",
    "X = readmit[features].values\n",
    "y = readmit.readmit30.values \n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size = .2, \n",
    "                                                random_state = 7, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data set is split, we can set up the regression and run it. There are a few important things happening in this process. First is the creation of a grid of possible values for C, which is a tuning parameter used when data cannot be separated into two categories with a clean, straight line in the x-y plane. When a best attempt at such a line is drawn, some observations that belong to one category might still lie on the \"wrong\" side of the separating line. To account for this dynamic, we introduce a tuning parameter into the math of logistic regression. This step ideally creates a value of C that is neither too high nor too low. The former could create a model that is too biased toward the training data to be generalizable, and the latter could create a model with too much variance to have much predictive value (kind of like a jack of all trades being a master of none). \n",
    "\n",
    "The second tool at hand is the GridSearchCV function. The grid search allows us to perform an exhaustive search for the best C in just one line of code. The process also uses cross validation and an l2 penalty, which both help manage variance and in turn keep the model from becoming too general to the point that its predictive value is weakened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001} 0.807966339411\n"
     ]
    }
   ],
   "source": [
    "# create grid, run grid search w/ logistic regression, find best C and its accuracy score\n",
    "\n",
    "C_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]} #dictionary w/ C as key and possible values\n",
    "weights = {0: .1, 1: .9} # class weights to address imbalance of dependent variable \n",
    "clf_grid = GridSearchCV(LogisticRegression(penalty='l2', class_weight = weights), C_grid, \n",
    "                        cv = 5, scoring = 'accuracy') \n",
    "clf_grid.fit(Xtrain, Ytrain) #fit model on training data\n",
    "\n",
    "print(clf_grid.best_params_, clf_grid.best_score_) #output best C and best accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80852734922861147"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model accuracy on training data \n",
    "clf_grid_best = LogisticRegression(C = clf_grid.best_params_['C'], penalty='l2', \n",
    "                                    class_weight = weights)\n",
    "clf_grid_best.fit(Xtrain, Ytrain)\n",
    "\n",
    "x_pred_train = clf_grid_best.predict(Xtrain) #capture predictions for Y based on data in X\n",
    "accuracy_score(x_pred_train, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82436981075622706"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model accuracy on test data \n",
    "clf_grid_best.fit(Xtest, Ytest)\n",
    "x_pred_test = clf_grid_best.predict(Xtest)\n",
    "accuracy_score(x_pred_test, Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to accuracy, it often helps to check another metric called precision-recall. Precision-recall analysis reports various percentages for how well a model does at classifying observations accurately for an outcome. I'll talk about this more once we produce the numbers in classification reports below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.84      0.89     48616\n",
      "          1       0.24      0.52      0.33      4859\n",
      "\n",
      "avg / total       0.88      0.81      0.84     53475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for training data \n",
    "report_train = classification_report(Ytrain, x_pred_train) #classify actual Y values in test data vs. those predicted in X\n",
    "print(report_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.86      0.90     12154\n",
      "          1       0.26      0.50      0.34      1215\n",
      "\n",
      "avg / total       0.88      0.82      0.85     13369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for test data\n",
    "report_test = classification_report(Ytest, x_pred_test) \n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision reflects the percentage of positive (i.e., readmitted within 30 days) predictions that are correct. If the model classifies 100 observations as positive, and 80 of those were in fact positive, then the model's precision is .8 (or 80%). \n",
    "\n",
    "Recall captures the percent of true positives that are classified as positive. Returning to our model's context, if there were 1,000 patients readmitted within thirty days and the model detected 850 of them, then the model's recall would be .85 (or 85%).\n",
    "\n",
    "Finally, the F1-score (the harmonic mean) shows the weighted average of precision and recall. It is a useful metric because it factors in both false positives and false negatives. The model here has an F1-score of .85, which is pretty good considering that 1.00 would be a perfect score and .5 would be as good as random guessing. However, this higher score masks the model's weak performance with positive cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score vs. ROC Curve\n",
    "\n",
    "The chosen model (with the best C and accuracy score) has an accuracy score of about .824, which means that about 82.4% of the model's predictions made about readmission within 30 days were correct. While accuracy can be an okay starting point to assess model performance, it isn't necessarily the best one for this case. Accuracy score is usually better when the number of observations is equal for each category within a feature, so let's look at another performance metric -- the area under an ROC curve -- next. \n",
    "\n",
    "An ROC curve reflects how well a model differentiates positive (readmission within 30 days, in our case) and negative outcomes. A model making all predictions correctly has an area of 1. A model that performs no better than random guessing has an area of 0.5. As we'll see in a moment, the curve itself plots the true positive rate against the false positive rate to help observers gauge performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01} 0.784683277694\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with area under ROC curve as metric \n",
    "C_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]} \n",
    "clf_grid_ROC = GridSearchCV(LogisticRegression(penalty='l2', class_weight = weights), \n",
    "                            C_grid, cv = 5, scoring = 'roc_auc')\n",
    "clf_grid_ROC.fit(Xtrain, Ytrain) \n",
    "print(clf_grid_ROC.best_params_, clf_grid_ROC.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78994358026510514"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check ROC performance on training set\n",
    "clf_grid_ROC_best = LogisticRegression(penalty='l2', class_weight = weights, C = clf_grid_ROC.best_params_['C'])\n",
    "clf_grid_ROC_best.fit(Xtrain, Ytrain)\n",
    "\n",
    "probs_train = clf_grid_ROC_best.predict_proba(Xtrain)\n",
    "preds_train = probs_train[:,1]\n",
    "roc_auc_score(Ytrain, preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79437791145322278"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check ROC performance on test set \n",
    "clf_grid_ROC_best.fit(Xtest, Ytest)\n",
    "\n",
    "probs_test = clf_grid_ROC_best.predict_proba(Xtest)\n",
    "preds_test = probs_test[:,1]\n",
    "roc_auc_score(Ytest, preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108623da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot ROC curve from test data\n",
    "fpr, tpr, threshold = roc_curve(Ytest, preds) #find true- and false-positive rates for relevant decision thresholds\n",
    "roc_auc = auc(fpr, tpr) #compute area under ROC curve using trapezoidal rule (not a binary classification here)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'blue', label = 'AUC = %0.4f' % roc_auc) #create line with AUC value for test data\n",
    "plt.plot([0, 1], [0, 1],'r--', label = 'AUC = .5') #create line with AUC=.5 for comparison\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A (theoretically) perfect ROC curve comprises a vertical line along the y-axis joined with a horizontal line at y = 1 (essentially an upside-down *L*. The closer our curve is to that ideal one, the better it is. So our model is looking pretty good at this point. Another line of comparison is the dotted red line, which represents at 50% success rate for binary predictions. If our model's line falls to this point, it is no better than randomly guessing would be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "A third way to evaluate model performance is a confustion matrix, which puts our model's predictions into four categories:\n",
    "\n",
    "- In the top-left quadrant is the number of observations classified as not readmitted within 30 days that were in fact not readmitted within 30 days. This is the true negative count. \n",
    "- In the top-right quadrant is the number of observations classified as readmitted within 30 days that were in fact not readmitted within 30 days. This is the false positive count. \n",
    "- In the lower left quadrant is the number of observations classified as not readmitted within 30 days that were in fact not readmitted within 30 days. This is the false negative count. \n",
    "- In the lower right quadrant is the number of observations classified as readmitted within 30 days that were in fact  readmitted within 30 days. This is the true negative count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0      1    All\n",
      "Actual                        \n",
      "0          40694   7922  48616\n",
      "1           2317   2542   4859\n",
      "All        43011  10464  53475\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for training data\n",
    "actual_train = pd.Series(Ytrain, name = 'Actual')\n",
    "predict_train = pd.Series(x_pred_train, name = 'Predicted') \n",
    "train_ct = pd.crosstab(actual_train, predict_train, margins = True) \n",
    "print(train_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for not readmitted: 0.837\n",
      "Training accuracy for readmitted (Recall): 0.523\n"
     ]
    }
   ],
   "source": [
    " # as percentages\n",
    "TN_train = train_ct.iloc[0,0] / train_ct.iloc[0,2]\n",
    "TP_train = train_ct.iloc[1,1] / train_ct.iloc[1,2]\n",
    "print('Training accuracy for not readmitted: {}'.format('%0.3f' % TN_train))\n",
    "print('Training accuracy for readmitted (Recall): {}'.format('%0.3f' % TP_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          10408  1746  12154\n",
      "1            602   613   1215\n",
      "All        11010  2359  13369\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for test data\n",
    "actual_test = pd.Series(Ytest, name = 'Actual')\n",
    "predict_test = pd.Series(x_pred_test, name = 'Predicted') \n",
    "test_ct = pd.crosstab(actual_test, predict_test, margins = True) \n",
    "print(test_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for not readmitted: 0.856\n",
      "Test accuracy for readmitted (Recall): 0.505\n"
     ]
    }
   ],
   "source": [
    " # as percentages\n",
    "TN_test = test_ct.iloc[0,0] / test_ct.iloc[0,2]\n",
    "TP_test = test_ct.iloc[1,1] / test_ct.iloc[1,2]\n",
    "print('Test accuracy for not readmitted: {}'.format('%0.3f' % TN_test))\n",
    "print('Test accuracy for readmitted (Recall): {}'.format('%0.3f' % TP_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does quite well predicting negative (labeled False in the matrices) cases, in which patients were not readmitted within thirty days. Percent accuracy is in the mid-80s. For positive cases, however, the model is just above 50% accuracy, which is just a little better than random chance. We'll see if the model can be improved with other algorithms outside logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Improvement Through Undersampling\n",
    "\n",
    "Although the accuracy for non-readmitted patients was quite good, the accuracy for positive cases (recall) was just slightly better than a random guess would be. Part of the reason for this issue might be the significant imblance in positive and negative outcomes. As we saw earlier, there are about 11 patients who were not readmitted within 30 days for every patient who was. In order to see if our model's performance is due to this imbalance, we can try the undersampling process with observations that did not show readmission within 30 days. Here, we'll use random undersampling to randomly choose fewer observations with the negative outcome in order to create a balance with positive outcomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 6074, 1: 6074})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n",
    "X = readmit[features].values #majority class to be undersampled\n",
    "Y = readmit.readmit30.values \n",
    "\n",
    "rus = RandomUnderSampler(random_state = 31)\n",
    "X_res, Y_res = rus.fit_sample(X, Y)\n",
    "Counter(Y_res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train, test, split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_res, Y_res, test_size = .2, \n",
    "                                                random_state = 31, stratify = Y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001} 0.721238938053\n"
     ]
    }
   ],
   "source": [
    "# create grid, run grid search w/ logistic regression, find best C and its accuracy score\n",
    "C_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]} \n",
    "clf_grid = GridSearchCV(LogisticRegression(penalty='l2'), C_grid, cv = 5, scoring = 'accuracy') \n",
    "clf_grid.fit(Xtrain, Ytrain) \n",
    "\n",
    "print(clf_grid.best_params_, clf_grid.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72844206626877961"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model accuracy on training data \n",
    "clf_grid_best = LogisticRegression(C = clf_grid.best_params_['C'], penalty='l2')\n",
    "clf_grid_best.fit(Xtrain, Ytrain)\n",
    "\n",
    "x_pred_train = clf_grid_best.predict(Xtrain) #capture predictions for Y based on data in X\n",
    "accuracy_score(x_pred_train, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66255144032921809"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model accuracy on test data \n",
    "clf_grid_best.fit(Xtest, Ytest)\n",
    "\n",
    "x_pred_test = clf_grid_best.predict(Xtest)\n",
    "accuracy_score(x_pred_test, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0           846   369  1215\n",
      "1           451   764  1215\n",
      "All        1297  1133  2430\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for logistic model w/ random undersampling\n",
    "actual = pd.Series(Ytest, name = 'Actual')\n",
    "predicted_rus = pd.Series(clf_grid_best.predict(Xtest), name = 'Predicted')\n",
    "ct_rus = pd.crosstab(actual, predicted_rus, margins = True)\n",
    "print(ct_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost accuracy for not readmitted: 0.696\n",
      "AdaBoost accuracy for readmitted (Recall): 0.629\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix with percentages\n",
    "TN_rus = ct_rus.iloc[0,0] / ct_rus.iloc[0,2]\n",
    "TP_rus = ct_rus.iloc[1,1] / ct_rus.iloc[1,2]\n",
    "print('AdaBoost accuracy for not readmitted: {}'.format('%0.3f' % TN_rus))\n",
    "print('AdaBoost accuracy for readmitted (Recall): {}'.format('%0.3f' % TP_rus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The undersampling approach improves the model's recall noticeably, although accuracy for negative cases suffered. We can try another technique called oversampling to see if further improvements are possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling (SMOTE)\n",
    "\n",
    "In addition to undersampling the majority class (not readmitted within 30 days), we can also try oversampling the minority class (readmitted within 30 days). Here, we'll use a common oversampling method called SMOTE (Synthetic Minority Oversampling Technique). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 60770, 1: 60770})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "X = readmit[features].values \n",
    "Y = readmit.readmit30.values #minority class to be oversampled\n",
    "\n",
    "sm = SMOTE(random_state = 31)\n",
    "X_resamp, Y_resamp = sm.fit_sample(X, Y)\n",
    "Counter(Y_resamp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train, test, split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_resamp, Y_resamp, test_size = .2, \n",
    "                                                random_state = 31, stratify = Y_resamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01} 0.724555701827\n"
     ]
    }
   ],
   "source": [
    "# create grid, run grid search w/ logistic regression, find best C and its accuracy score\n",
    "C_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]} \n",
    "clf_grid = GridSearchCV(LogisticRegression(penalty='l2'), C_grid, cv = 5, scoring = 'accuracy') \n",
    "clf_grid.fit(Xtrain, Ytrain) \n",
    "\n",
    "print(clf_grid.best_params_, clf_grid.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72503908178377485"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model accuracy on training data \n",
    "clf_grid_best = LogisticRegression(C = clf_grid.best_params_['C'], penalty='l2')\n",
    "clf_grid_best.fit(Xtrain, Ytrain)\n",
    "\n",
    "x_pred_train = clf_grid_best.predict(Xtrain) #capture predictions for Y based on data in X\n",
    "accuracy_score(x_pred_train, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72766167516866875"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model accuracy on test data \n",
    "clf_grid_best.fit(Xtest, Ytest)\n",
    "\n",
    "x_pred_test = clf_grid_best.predict(Xtest)\n",
    "accuracy_score(x_pred_test, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0      1    All\n",
      "Actual                        \n",
      "0           9487   2667  12154\n",
      "1           3953   8201  12154\n",
      "All        13440  10868  24308\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix with SMOTE oversampling\n",
    "actual = pd.Series(Ytest, name = 'Actual')\n",
    "predicted_sm = pd.Series(clf_grid_best.predict(Xtest), name = 'Predicted')\n",
    "ct_sm = pd.crosstab(actual, predicted_sm, margins = True)\n",
    "print(ct_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for not readmitted: 0.781\n",
      "Accuracy for readmitted (Recall): 0.675\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix with percentages\n",
    "TN_sm = ct_sm.iloc[0,0] / ct_sm.iloc[0,2]\n",
    "TP_sm = ct_sm.iloc[1,1] / ct_sm.iloc[1,2]\n",
    "print('Accuracy for not readmitted: {}'.format('%0.3f' % TN_sm))\n",
    "print('Accuracy for readmitted (Recall): {}'.format('%0.3f' % TP_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The oversampling approach improved accuracy for both positive and negative cases when compared with undersampling. The global accuracy (about 73%) is a little lower than it was in the original model (about 80%), but the trade-off to improve recall is worth it. Predictive value with respect to the positive class is more valuable, so the oversampling model is our best choice with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
